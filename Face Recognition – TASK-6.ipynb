{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Recognition – Unlock Your Computer With Your Face!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 1 - Create Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-1-b50d482c18ad>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "def captureImages(user,path):\n",
    "    count = 0\n",
    "    cap=cv2.VideoCapture('http:/192.168.43.1:8080/video')\n",
    "    # Collect 100 samples of your face from webcam input\n",
    "    print(path)\n",
    "    while True:\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Photo not clicked\")\n",
    "            continue\n",
    "        if face_extractor(frame) is not None:\n",
    "            count += 1\n",
    "            face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Save file in specified directory with unique name\n",
    "            file_name_path = path+ user + str(count) + '.jpg'\n",
    "            print(file_name_path)\n",
    "            cv2.imwrite(file_name_path, face)\n",
    "\n",
    "            # Put count on images and display live count\n",
    "            cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Cropper', face)\n",
    "\n",
    "        else:\n",
    "            print(\"Face not found\")\n",
    "            pass\n",
    "\n",
    "        if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "            break\n",
    "\n",
    "    print(\"Collecting Samples Complete\")\n",
    "    cv2.destroyAllWindows()          \n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./users/\n",
      "['.ipynb_checkpoints', '50_Startups.csv', 'churn_model.ipynb', 'Churn_Modelling.csv', 'cnn-cat-dog-model (1).h5', 'cnn-model.h5', 'CNN.ipynb', 'diabetes_model.ipynb', 'emailsender.py', 'face', 'Face Recognition – TASK-6.ipynb', 'haarcascade_frontalface_default.xml', 'marks.csv', 'marks.pk1', 'mgr.py', 'multi linear regression model.ipynb', 'myweightheight.h5', 'pima-indians-diabetes.data.csv', 'pywhatkit_dbs.txt', 'setup.py', 'simple linear regression model.ipynb', 'single_prediction', 'temp.py', 'testing_set', 'titanic binary classification.ipynb', 'titanic_test.csv', 'titanic_train.csv', 'training_set', 'Untitled.ipynb', 'users', 'weight-height.csv', 'weight-height.ipynb']\n",
      "Enter User 1 ID (Numerical): 1\n",
      "./users/\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "./users/11.jpg\n",
      "./users/12.jpg\n",
      "./users/13.jpg\n",
      "./users/14.jpg\n",
      "./users/15.jpg\n",
      "./users/16.jpg\n",
      "./users/17.jpg\n",
      "./users/18.jpg\n",
      "./users/19.jpg\n",
      "./users/110.jpg\n",
      "./users/111.jpg\n",
      "./users/112.jpg\n",
      "./users/113.jpg\n",
      "./users/114.jpg\n",
      "./users/115.jpg\n",
      "./users/116.jpg\n",
      "./users/117.jpg\n",
      "./users/118.jpg\n",
      "./users/119.jpg\n",
      "./users/120.jpg\n",
      "./users/121.jpg\n",
      "./users/122.jpg\n",
      "./users/123.jpg\n",
      "./users/124.jpg\n",
      "./users/125.jpg\n",
      "./users/126.jpg\n",
      "./users/127.jpg\n",
      "./users/128.jpg\n",
      "./users/129.jpg\n",
      "./users/130.jpg\n",
      "./users/131.jpg\n",
      "./users/132.jpg\n",
      "./users/133.jpg\n",
      "./users/134.jpg\n",
      "./users/135.jpg\n",
      "./users/136.jpg\n",
      "./users/137.jpg\n",
      "./users/138.jpg\n",
      "./users/139.jpg\n",
      "./users/140.jpg\n",
      "./users/141.jpg\n",
      "./users/142.jpg\n",
      "./users/143.jpg\n",
      "./users/144.jpg\n",
      "./users/145.jpg\n",
      "./users/146.jpg\n",
      "./users/147.jpg\n",
      "./users/148.jpg\n",
      "./users/149.jpg\n",
      "./users/150.jpg\n",
      "./users/151.jpg\n",
      "./users/152.jpg\n",
      "./users/153.jpg\n",
      "./users/154.jpg\n",
      "./users/155.jpg\n",
      "./users/156.jpg\n",
      "./users/157.jpg\n",
      "./users/158.jpg\n",
      "./users/159.jpg\n",
      "./users/160.jpg\n",
      "./users/161.jpg\n",
      "./users/162.jpg\n",
      "./users/163.jpg\n",
      "./users/164.jpg\n",
      "./users/165.jpg\n",
      "./users/166.jpg\n",
      "./users/167.jpg\n",
      "./users/168.jpg\n",
      "./users/169.jpg\n",
      "./users/170.jpg\n",
      "./users/171.jpg\n",
      "./users/172.jpg\n",
      "./users/173.jpg\n",
      "./users/174.jpg\n",
      "./users/175.jpg\n",
      "./users/176.jpg\n",
      "./users/177.jpg\n",
      "./users/178.jpg\n",
      "./users/179.jpg\n",
      "./users/180.jpg\n",
      "./users/181.jpg\n",
      "./users/182.jpg\n",
      "./users/183.jpg\n",
      "./users/184.jpg\n",
      "./users/185.jpg\n",
      "./users/186.jpg\n",
      "./users/187.jpg\n",
      "./users/188.jpg\n",
      "./users/189.jpg\n",
      "./users/190.jpg\n",
      "./users/191.jpg\n",
      "./users/192.jpg\n",
      "./users/193.jpg\n",
      "./users/194.jpg\n",
      "./users/195.jpg\n",
      "./users/196.jpg\n",
      "./users/197.jpg\n",
      "./users/198.jpg\n",
      "./users/199.jpg\n",
      "./users/1100.jpg\n",
      "Collecting Samples Complete\n",
      "Enter User 2 ID (Numerical): 2\n",
      "./users/\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "./users/21.jpg\n",
      "./users/22.jpg\n",
      "./users/23.jpg\n",
      "./users/24.jpg\n",
      "./users/25.jpg\n",
      "./users/26.jpg\n",
      "./users/27.jpg\n",
      "./users/28.jpg\n",
      "./users/29.jpg\n",
      "./users/210.jpg\n",
      "./users/211.jpg\n",
      "./users/212.jpg\n",
      "./users/213.jpg\n",
      "./users/214.jpg\n",
      "./users/215.jpg\n",
      "./users/216.jpg\n",
      "./users/217.jpg\n",
      "./users/218.jpg\n",
      "./users/219.jpg\n",
      "./users/220.jpg\n",
      "./users/221.jpg\n",
      "./users/222.jpg\n",
      "./users/223.jpg\n",
      "./users/224.jpg\n",
      "./users/225.jpg\n",
      "./users/226.jpg\n",
      "./users/227.jpg\n",
      "./users/228.jpg\n",
      "./users/229.jpg\n",
      "./users/230.jpg\n",
      "./users/231.jpg\n",
      "./users/232.jpg\n",
      "./users/233.jpg\n",
      "./users/234.jpg\n",
      "./users/235.jpg\n",
      "./users/236.jpg\n",
      "./users/237.jpg\n",
      "./users/238.jpg\n",
      "./users/239.jpg\n",
      "./users/240.jpg\n",
      "./users/241.jpg\n",
      "./users/242.jpg\n",
      "./users/243.jpg\n",
      "./users/244.jpg\n",
      "./users/245.jpg\n",
      "./users/246.jpg\n",
      "./users/247.jpg\n",
      "./users/248.jpg\n",
      "./users/249.jpg\n",
      "./users/250.jpg\n",
      "./users/251.jpg\n",
      "./users/252.jpg\n",
      "./users/253.jpg\n",
      "./users/254.jpg\n",
      "./users/255.jpg\n",
      "./users/256.jpg\n",
      "./users/257.jpg\n",
      "./users/258.jpg\n",
      "./users/259.jpg\n",
      "./users/260.jpg\n",
      "./users/261.jpg\n",
      "./users/262.jpg\n",
      "./users/263.jpg\n",
      "./users/264.jpg\n",
      "./users/265.jpg\n",
      "./users/266.jpg\n",
      "./users/267.jpg\n",
      "./users/268.jpg\n",
      "./users/269.jpg\n",
      "./users/270.jpg\n",
      "./users/271.jpg\n",
      "./users/272.jpg\n",
      "./users/273.jpg\n",
      "./users/274.jpg\n",
      "./users/275.jpg\n",
      "./users/276.jpg\n",
      "./users/277.jpg\n",
      "./users/278.jpg\n",
      "./users/279.jpg\n",
      "./users/280.jpg\n",
      "./users/281.jpg\n",
      "./users/282.jpg\n",
      "./users/283.jpg\n",
      "./users/284.jpg\n",
      "./users/285.jpg\n",
      "./users/286.jpg\n",
      "./users/287.jpg\n",
      "./users/288.jpg\n",
      "./users/289.jpg\n",
      "./users/290.jpg\n",
      "./users/291.jpg\n",
      "./users/292.jpg\n",
      "./users/293.jpg\n",
      "./users/294.jpg\n",
      "./users/295.jpg\n",
      "./users/296.jpg\n",
      "./users/297.jpg\n",
      "./users/298.jpg\n",
      "./users/299.jpg\n",
      "./users/2100.jpg\n",
      "Collecting Samples Complete\n",
      "4.5.2\n",
      "Model trained sucessefully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir,mkdir\n",
    "from os.path import isfile, join, exists\n",
    "\n",
    "# Get the training data we previously made\n",
    "data_path = './users/'\n",
    "print(data_path)\n",
    "if not exists(data_path):\n",
    "    mkdir(data_path)\n",
    "print(listdir())\n",
    "\n",
    "captureImages(input(\"Enter User 1 ID (Numerical): \"),data_path)\n",
    "\n",
    "captureImages(input(\"Enter User 2 ID (Numerical): \"),data_path)\n",
    "\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "print(cv2.__version__)\n",
    "# Create arrays for training data and labels\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    lid=int(onlyfiles[i].split('.')[0])\n",
    "    Labels.append(lid)\n",
    "\n",
    "# Create a numpy array for both training data and labels\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "# Initialize facial recognizer\n",
    "# model = cv2.face.createLBPHFaceRecognizer()\n",
    "# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "# pip install opencv-contrib-python\n",
    "# model = cv2.createLBPHFaceRecognizer()\n",
    "\n",
    "vimal_model  = cv2.face_LBPHFaceRecognizer.create()\n",
    "# Let's train our model \n",
    "vimal_model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"Model trained sucessefully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Run Our Facial Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:14: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:14: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-4-35cbf59a3037>:14: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whatapp message send successfully\n",
      "········\n",
      "Email sent Successfully!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pywhatkit as pkt\n",
    "import getpass\n",
    "import boto3,time\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture('http://192.168.43.1:8080/video')\n",
    "flag=False\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image, face = face_detector(frame)\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        results = vimal_model.predict(face)\n",
    "        # harry_model.predict(face)\n",
    "        \n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            user = str(results[0])[0]\n",
    "            display_string = str(confidence) + '% Confident it is User ' + user\n",
    "            \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "        \n",
    "        if confidence > 80 and user=='1':\n",
    "            cv2.putText(image, \"Hey User 1\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image ) \n",
    "            \n",
    "            pkt.sendwhatmsg_instantly(\"+917073973656\",\"Hlo,Task Completed\")\n",
    "            print(\"whatapp message send successfully\")\n",
    "            p = getpass.getpass()\n",
    "            pkt.send_mail(\"purusoni220@gmail.com\",p,\"test mail\",\"Task completed\",\"rahulbairwabhl@gmail.com\")\n",
    "            \n",
    "            break\n",
    "        elif confidence > 80 and user=='2':\n",
    "            cv2.putText(image, \"Hey User 2\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            \n",
    "            print(\"Launching EC2 Instance....\")\n",
    "            \n",
    "            client=boto3.client(\"ec2\")\n",
    "            ec2_id = client.run_instances(\n",
    "                ImageId=\"ami-0ad704c126371a549\",\n",
    "                MinCount=1,\n",
    "                MaxCount=1,\n",
    "                InstanceType=\"t2.micro\",\n",
    "                KeyName=\"AWS-KEY\",\n",
    "                SubnetId=\"subnet-10e00b7b\",\n",
    "                SecurityGroupIds=[\"sg-02b328240cd51089d\"]\n",
    "\n",
    "            )\n",
    "            print(\"Instance Launched successfully...\")\n",
    "            print(\"Creating EBS volume of 5 GB...\")\n",
    "            \n",
    "            volume_id = client.create_volume( AvailabilityZone='ap-south-1a',\n",
    "                  Size=5,\n",
    "                  VolumeType='gp2',\n",
    "                  TagSpecifications=[\n",
    "                      {\n",
    "                          'ResourceType': 'volume',\n",
    "                          'Tags': [\n",
    "                              {\n",
    "                                  'Key': 'Name',\n",
    "                                  'Value': 'volume_task'\n",
    "                              },\n",
    "                          ]\n",
    "                      },\n",
    "                  ],)\n",
    "            \n",
    "            print(\"Please Wait! While Instance is Launching.....\")\n",
    "            time.sleep(30)\n",
    "            \n",
    "            instanceid=ec2_id[\"Instances\"][0][\"InstanceId\"]\n",
    "            vid = volume_id[\"VolumeId\"]\n",
    "            print(instanceid,vid)\n",
    "            print(\"Volume  created successfully...\\n\")\n",
    "            print(\" Attaching EBS volume to EC2 instance...\")\n",
    "            client.attach_volume(\n",
    "                        Device='/dev/xvdb',\n",
    "                        InstanceId=instanceid,\n",
    "                        VolumeId = vid            \n",
    "                        ) \n",
    "            print(\"volume attached successfully...\")\n",
    "            break\n",
    "        else:\n",
    "            cv2.putText(image, \"I dont know, how r u\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            \n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
